{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chriszhengao/data-processing-for-rsmc-tokyo-best-track-data?scriptVersionId=144988411\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## *At the beginning...*\nHi guys!  \nNice to meet you all!  \nI just wanna say this is my very first time \"contributing\" (maybe it is a totally trash lol) some works online..  \nI know the code or the content would be kind of in chaos...?   \nIt's more like a self-adventure i would say..  \nyea.. it's just recorded all the thoughts i had during the journey of my self-learning and exploring!  \nand what's more...   \nreally looking forward your suggestion!  \n","metadata":{}},{"cell_type":"markdown","source":"## *Downloading Latest Version of Data from JMA Website*\n","metadata":{}},{"cell_type":"markdown","source":"Directly download the data from the website would be a good approach, because their update the data from time to time, meaning that we can always get the latest data.\n","metadata":{}},{"cell_type":"code","source":"#imports\nimport requests\nimport zipfile\nimport os\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:53:28.501134Z","iopub.execute_input":"2023-10-02T09:53:28.501575Z","iopub.status.idle":"2023-10-02T09:53:29.000908Z","shell.execute_reply.started":"2023-10-02T09:53:28.501543Z","shell.execute_reply":"2023-10-02T09:53:28.999728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Preview of the Text File Content*\n","metadata":{}},{"cell_type":"markdown","source":"*Without real example as the reference, it would still be hard for us to understand how they constructed the dataset, so let's get the real data from their website*\n","metadata":{}},{"cell_type":"code","source":"#define the URL and the file name\nfile_url = 'https://www.jma.go.jp/jma/jma-eng/jma-center/rsmc-hp-pub-eg/Besttracks/bst_all.zip'\nfile_name = 'bst_all.zip'\n\n#define the file path\nextract_path = r'/kaggle/working/'\n\n#downloading the file from JMA website\nresponse = requests.get(file_url)\nwith open(file_name, 'wb') as file:\n    file.write(response.content)\n\n#decompression of file\nwith zipfile.ZipFile(file_name, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n\n#delete the ZIP file\nos.remove(file_name)\n\n#the file path of decompressed txt file\nfile_path = r'/kaggle/working/bst_all.txt'\n\n#read the number of lines(including hearder(s))\nline_count = 0\nheader_line_count = 0\nwith open(file_path,'r') as file:\n    for line in file:\n        line_count += 1\n        if line.startswith(\"66666\"):\n            header_line_count += 1\nprint('Total lines of data: ', line_count, ' line(s)\\n')\n\n#print the headers of each recorded data\nprint('Total lines for Each Tropical Cyclone: ',header_line_count, ' line(s)\\n')\n\n#open the file and read the first 10 lines\nwith open(file_path, 'r', encoding='utf-8') as file:\n    first_10_lines = [next(file) for _ in range(10)]\n\n#divider\nprint('-------------------------------')\n\n#print out first 10 lines\nprint('\\nFirst 10 lines:\\n')\nfor line in first_10_lines:\n    print(line, end='')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:53:37.54916Z","iopub.execute_input":"2023-10-02T09:53:37.550058Z","iopub.status.idle":"2023-10-02T09:53:39.162704Z","shell.execute_reply.started":"2023-10-02T09:53:37.55001Z","shell.execute_reply":"2023-10-02T09:53:39.161589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You might be wondering why I used **66666**, let's now take a look of how JMA explained that!","metadata":{}},{"cell_type":"markdown","source":"## *Format of RSMC Best Track Data*","metadata":{}},{"cell_type":"markdown","source":"Basically, the raw data has to main parts,  \nfirst part is *Header Line* part,  \nsecond part is *Data Line* part.  \n\nEach cyclone has 1 line of *Header Line*,  \nwith multiple lines of *Data Line* part.  \n\nLet's see how JMA explain the data.","metadata":{}},{"cell_type":"markdown","source":"### *Header Line for Each Tropical Cyclone*","metadata":{}},{"cell_type":"markdown","source":"```\n    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80   \n::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|   \nAAAAA BBBB  CCC DDDD EEEE F G HHHHHHHHHHHHHHHHHHHH              IIIIIIII   \n\n\nSample:   \n66666 9119  150 0045 9119 0 6             MIRREILE              19920701   \n          \n\nAAAAA    5 columns     <Indicator> '66666'   \nBBBB     4 columns     <International number ID>    \n                          Last two digits of calendar year followed by 2-digit serial    \n                          number ID of the storm of Tropical Storm (TS) intensity or    \n                          greater   \nCCC      3 columns     <Number of data lines>   \nDDDD     4 columns     <Tropical cyclone number ID>   \n                          Serial number ID of the storm of intensity with maximum    \n                          sustained wind speed of 28 kt (near gale) or  greater   \nEEEE     4 columns     <International number ID> Replicate BBBB   \nF        1 column      <Flag of the last data line>    \n                          0 : Dissipation   \n                          1 : Going out of the responsible area of RSMC Tokyo-Typhoon Center   \nG        1 column      <Difference between the time of the last data and the time of    \n                          the final analysis> Unit : hour   \nH...H   20 columns     <Name of the storm>   \nI...I    8 columns     <Date of the latest revision>   \n```","metadata":{}},{"cell_type":"markdown","source":"### *Data Lines*","metadata":{}},{"cell_type":"markdown","source":"```\n    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80\n    \n::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|\n\nAAAAAAAA BBB C DDD EEEE FFFF     GGG     HIIII JJJJ KLLLL MMMM         P\n\n\nSample:\n91092706 002 5 325 1293  935     095     30180 0140 30400 0260         #\n          \nA...A    8 columns     <Time of analysis> yymmddhh (UTC)\nBBB      3 columns     <Indicator> '002'\nC        1 column      <Grade> 1 : Not used\n                               2 : Tropical Depression (TD)\n                               3 : Tropical Storm (TS)\n                               4 : Severe Tropical Storm (STS)\n                               5 : Typhoon (TY)\n                               6 : Extra-tropical Cyclone (L)\n                               7 : Just entering into the responsible area of RSMC Tokyo-Typhoon Center\n                               8 : Not used\n                               9 : Tropical Cyclone of TS intensity or higher\nDDD      3 columns     <Latitude of the center> Unit : 0.1 degree\nEEEE     4 columns     <Longitude of the center> Unit : 0.1 degree\nFFFF     4 columns     <Central pressure> Unit : hPa\nGGG      3 columns     <Maximum sustained wind speed> Unit : knot (kt)\nH        1 column      <Direction of the longest radius of 50kt winds or greater>\n                          0 : No direction (Longest radius of 50kt winds is 0)\n                          1 : Northeast (NE)\n                          2 : East (E)\n                          3 : Southeast (SE)\n                          4 : South (S)\n                          5 : Southwest (SW)\n                          6 : West (W)\n                          7 : Northwest (NW)\n                          8 : North (N)\n                          9 : (symmetric circle)\nIIII     4 columns     <The longest radius of 50kt winds or greater>\n                          Unit : nautical mile (nm)\nJJJJ     4 columns     <The shortest radius of 50kt winds or greater>\n                          Unit : nautical mile (nm)\nK        1 column      <Direction of the longest radius of 30kt winds or greater>\n                          0 : No direction (Longest radius of 30kt winds is 0)\n                          1 : Northeast (NE)\n                          2 : East (E)\n                          3 : Southeast (SE)\n                          4 : South (S)\n                          5 : Southwest (SW)\n                          6 : West (W)\n                          7 : Northwest (NW)\n                          8 : North (N)\n                          9 : (symmetric circle)\nLLLL     4 columns     <The longest radius of 30kt winds or greater>\n                          Unit : nautical mile (nm)\nMMMM     4 columns     <The shortest radius of 30kt winds or greater>\n                          Unit : nautical mile (nm)\nP        1 column      <Indicator of landfall or passage>\n                          Landfall or passage over the Japanese islands occurred within \n                          one hour after the time of the analysis with this indicator.\n\n          \n(All data are recorded in the ASCII code.)\n```","metadata":{}},{"cell_type":"markdown","source":"__________________________________________________________\n\n   \nAs stated in the \"*Format of RSMC Best Track Data*\":\n__________________________________________________________\n\n**The first line denotes to the \"*Header Line for Each Tropical Cyclone*\"**\n**Each digit has its position as explained by the JMA**","metadata":{}},{"cell_type":"markdown","source":"```\n    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80\n::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|\nAAAAA BBBB  CCC DDDD EEEE F G HHHHHHHHHHHHHHHHHHHH              IIIIIIII\n\n↑     ↑      ↑  ↑    ↑    ↑ ↑ ↑                                 ↑\n66666 5101   10      5101 0 6                                   19901017\n```","metadata":{}},{"cell_type":"markdown","source":"**Example:**   \n   \n*6666*       as stated as *AAAAA*,  as the *indicator*.   \n*5101*       as *BBBB*,             as the *International number ID*   \n*10*         as *CCC*,              as the *Number of data lines*   \n*5101*       as *EEEE*,             simply replicates *BBBB*   \n*0*          as *F*,                as the *Flag of the last data line*   \n*6*          as *G*,                as the *Difference between the time of the last data and the time   of the final analysis*   \n*19901017*   as *IIIIIIII*,         as the *Date of the latest revision*   ","metadata":{}},{"cell_type":"markdown","source":"**The rest of the lines refer to \"*Data lines*\"**\n","metadata":{}},{"cell_type":"markdown","source":"```\n    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80\n::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|::::+::::|\nAAAAAAAA BBB C DDD EEEE FFFF     GGG     HIIII JJJJ KLLLL MMMM         P\n\n↑        ↑   ↑ ↑   ↑    ↑        ↑       ↑     ↑     ↑    ↑            ↑\n51021906 002 2 200 1385 1010                                                    \n51021912 002 2 200 1385 1010                                                    \n51021918 002 2 230 1421 1000                                                    \n51022000 002 9 250 1460  994                                                    \n51022006 002 9 276 1506  994                                                    \n51022012 002 9 289 1533  994                                                    \n51022018 002 9 313 1575  992                                                    \n51022100 002 9 326 1621  990                                                    \n51022106 002 6 339 1660  990  \n```","metadata":{}},{"cell_type":"markdown","source":"**Example:**   \n\n*51021906*       as stated as *AAAAA*,  as the *Time of analysis*   \n*002*            as *BBBB*,             as the *Indicator*   \n*2*              as *C*,                as the *Grade*   \n*200*            as *DDD*,              as the *Latitude of the center*   \n*1385*           as *EEEE*,             as the *Longitude of the center*   \n*101*            as *FFFF*,             as the *Central pressure*   \n   \nDue to the limit of the detect devices in the past, some of the data was missed.","metadata":{}},{"cell_type":"markdown","source":"### *Extracting Header Lines*   \nand convert them into CSV file.","metadata":{}},{"cell_type":"code","source":"import csv\n\n# read TXT file\nwith open(r'/kaggle/working/bst_all.txt', 'r') as txt_file:\n    lines = txt_file.readlines()\ncount = 0\n# create a CSV file and write it\nwith open(r'/kaggle/working/data_head0.csv', 'w', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file)\n    # column names,according to the JMA format explaination\n    csv_writer.writerow(['Indicator', 'International number ID 1', 'Number of data lines', \n                         'Tropical cyclone number ID', 'International number ID 2','Flag of the last data line', \n                         'Difference between the time of the last data and the time of the final analysis',\n                         'Name of the storm', 'Date of the latest revision'])\n\n    # Find the lines that start with 66666 which is the indicator of Header Lines\n    for line in lines:\n        if line.startswith('66666'):\n            try:\n                # according to the index numbers provided by JMA.\n                Indicator = line[0:5]\n                International_number_ID = line[6:10]\n                Number_of_data_lines = line[12:15]\n                Tropical_cyclone_number_ID = line[16:20]\n                International_number_ID2 = line[21:25]\n                Flag_of_last_data_line = line[26]\n                Difference = line[28]\n                Name_of_the_storm = line[30:50]\n                Date_of_latest_revision = line[64:72]\n\n                X = int(line[12:15])  #number of data lines and duplicate the line\n                for _ in range(X):\n                    csv_writer.writerow([Indicator, International_number_ID, Number_of_data_lines, \n                                         Tropical_cyclone_number_ID, International_number_ID2, \n                                         Flag_of_last_data_line, Difference, \n                                         Name_of_the_storm.strip(), Date_of_latest_revision.strip()])\n            except (ValueError, IndexError):\n                pass  \n\nprint(\"Extracted and Saved as data_head0.csv!\")\n\ndata_head0 = pd.read_csv(r'/kaggle/working/data_head0.csv')\ndata_head0.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:00:17.005612Z","iopub.execute_input":"2023-10-02T10:00:17.006215Z","iopub.status.idle":"2023-10-02T10:00:17.311271Z","shell.execute_reply.started":"2023-10-02T10:00:17.006171Z","shell.execute_reply":"2023-10-02T10:00:17.310013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Extracting Data Lines*   \nThis step is to delete the *Header Lines* in the original TXT file.","metadata":{}},{"cell_type":"code","source":"input_file_path = r'/kaggle/working/bst_all.txt'\noutput_file_path = r'/kaggle/working/data_no_headers.txt'\n\ntry:\n    with open(input_file_path, 'r', encoding='utf-8') as input_file:\n        lines = input_file.readlines()\n\n    filtered_lines = [line for line in lines if not line.startswith('66666')]\n\n    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n        output_file.writelines(filtered_lines)\n\n    result = len(filtered_lines)\n    print(f\"Deleted the lines start with '66666'，Saved to {output_file_path}, it has {result} lines\")\nexcept FileNotFoundError:\n    print(\"File does not exist!\")\nexcept Exception as e:\n    print(f\"Error：{str(e)}\")\n    print(\"Failed!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:01:19.114811Z","iopub.execute_input":"2023-10-02T10:01:19.1152Z","iopub.status.idle":"2023-10-02T10:01:19.18238Z","shell.execute_reply.started":"2023-10-02T10:01:19.115173Z","shell.execute_reply":"2023-10-02T10:01:19.181164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert the remaining *Data Lines* part into CSV file.\n","metadata":{}},{"cell_type":"code","source":"# read the previous txt file that has only lines with no header lines\nwith open(r'/kaggle/working/data_no_headers.txt', 'r') as new_txt_file:\n    new_lines = new_txt_file.readlines()\n\n# create a new CSV file to record the data lines data\nwith open(r'/kaggle/working/data_dataLines0.csv', 'w', newline='') as new_csv_file:\n    csv_writer = csv.writer(new_csv_file)\n\n    # column names, according to the explaination provided by JMA.\n    csv_writer.writerow(['Time of analysis', 'Indicator', 'Grade', 'Latitude of the center',\n                         'Longitude of the center', 'Central pressure', 'Maximum sustained wind speed',\n                         'Direction of the longest radius of 50kt winds or greater',\n                         'The longest radius of 50kt winds or greater',\n                         'The shortest radius of 50kt winds or greater',\n                         'Direction of the longest radius of 30kt winds or greater',\n                         'The longest radius of 30kt winds or greater',\n                         'The shortest radius of 30kt winds or greater',\n                         'Indicator of landfall or passage'])\n\n    for line in new_lines:\n        # according to the index numbers provided by JMA.\n        Time_of_analysis = line[0:8]\n        Indicator = line[9:12]\n        Grade = line[13]\n        Latitude_of_the_center = line[15:18]\n        Longitude_of_the_center = line[19:23]\n        Central_pressure = line[24:28]\n        Maximum_sustained_wind_speed = line[33:36]\n        Direction_of_the_longest_radius_of_50kt_winds_or_greater = line[41]\n        The_longest_radius_of_50kt_winds_or_greater = line[42:46]\n        The_shortest_radius_of_50kt_winds_or_greater = line[47:51]\n        Direction_of_the_longest_radius_of_30kt_winds_or_greater = line[52]\n        The_longest_radius_of_30kt_winds_or_greater = line[53:57]\n        The_shortest_radius_of_30kt_winds_or_greater = line[58:62]\n        Indicator_of_landfall_or_passage = line[71]\n        \n        csv_writer.writerow([Time_of_analysis, Indicator, Grade, Latitude_of_the_center,\n                            Longitude_of_the_center, Central_pressure, Maximum_sustained_wind_speed,\n                            Direction_of_the_longest_radius_of_50kt_winds_or_greater,\n                            The_longest_radius_of_50kt_winds_or_greater,\n                            The_shortest_radius_of_50kt_winds_or_greater,\n                            Direction_of_the_longest_radius_of_30kt_winds_or_greater,\n                            The_longest_radius_of_30kt_winds_or_greater,\n                            The_shortest_radius_of_30kt_winds_or_greater,\n                            Indicator_of_landfall_or_passage\n                            ])\n\nprint(\"Extracted and Saved as data_dataLines0.csv!\")\n\ndata_dataLines0 = pd.read_csv(r'/kaggle/working/data_dataLines0.csv')\ndata_dataLines0.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:02:19.346657Z","iopub.execute_input":"2023-10-02T10:02:19.347071Z","iopub.status.idle":"2023-10-02T10:02:19.760434Z","shell.execute_reply.started":"2023-10-02T10:02:19.347043Z","shell.execute_reply":"2023-10-02T10:02:19.759454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After extracted 2 parts of the raw data set, we shall put them together;    \n*Header Lines* & *Data Lines*","metadata":{}},{"cell_type":"code","source":"# header lines\ncsv1 = pd.read_csv(r'/kaggle/working/data_head0.csv')\n\n# data lines\ncsv2 = pd.read_csv(r'/kaggle/working/data_dataLines0.csv')\n\n# make sure their have same number of rows\nif len(csv1) != len(csv2):\n    raise ValueError(\"the number of rows is not matched!\")\n\n# merge them together and put data lines part on the right side of header lines. \nmerged_csv = pd.concat([csv1, csv2], axis=1)\n\n# merged and put them into a new file.\nmerged_csv.to_csv(r'/kaggle/working/data_header_data_merged.csv', index=False)\n\nmerged_csv.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:03:12.913436Z","iopub.execute_input":"2023-10-02T10:03:12.91388Z","iopub.status.idle":"2023-10-02T10:03:13.52547Z","shell.execute_reply.started":"2023-10-02T10:03:12.913844Z","shell.execute_reply":"2023-10-02T10:03:13.524336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Data Cleaning*\n","metadata":{}},{"cell_type":"markdown","source":"Let's have a little revision of every column to check which columns we should remain.\n","metadata":{}},{"cell_type":"markdown","source":"**1. Indicator**  ❌*since it is just for us to determine it is a line for header line*   \n**2. International number ID** 🖋️*needs to add explaination*      \n```\nLast two digits of calendar year followed by 2-digit serial \nnumber ID of the storm of Tropical Storm (TS) intensity or \ngreater\n```\n**3. Number of data lines** ❌*since after emerging the header lines and the data lines, we already knew that how many lines are there*  \n**4. Tropical cyclone number ID** ❌*since we alreay had an unique number for each of the cyclone*     \n```\nSerial number ID of the storm of intensity with maximum   \nsustained wind speed of 28 kt (near gale) or  greater  \n```\n**5. International number ID 2** ❌*since it just simply duplicates the indicator*  \n```\nReplicate BBBB \n```\n**6. Flag of the last data line** ❌ *since it just denotes the status of the last data*  \n```\n0 : Dissipation  \n1 : Going out of the responsible area of RSMC Tokyo-Typhoon Center  \n```\n**7. Difference between the time of the last data and the time of the final analysis** ❌ *not necessary because the difference of the time between last data and final analysis won't be effective with further analysis*   \n```\nUnit : hour  \n```\n**8. Name of the storm**    \n**10. Date of the latest revision**❌ *latest revision rarely changed*  \n_______________________________________\n\n**11. Time of analysis** 🖋️*needs to convert into time format*    \n```\nyymmddhh (UTC)\n```\n**12.Indicator** ❌ *just for us to know it is a line from data lines*   \n```\n'002'\n```\n**13. Grade** 🖋️ *needs to convert to denoted String from used Integer*  \n```\n1 : Not used\n2 : Tropical Depression (TD)\n3 : Tropical Storm (TS)\n4 : Severe Tropical Storm (STS)\n5 : Typhoon (TY)\n6 : Extra-tropical Cyclone (L)\n7 : Just entering into the responsible area of RSMC Tokyo-Typhoon Center\n8 : Not used\n9 : Tropical Cyclone of TS intensity or higher\n```\n**14. Latitude of the center** 🖋️*needs to convert by multiplying 0.1 degree*  \n```\nUnit : 0.1 degree\n```\n**15. Longitude of the center** 🖋️*needs to convert by multiplying 0.1 degree*  \n```\nUnit : 0.1 degree\n```\n**16. Central pressure** 🖋️*needs to add hPa*  \n```\nUnit : hPa\n```\n**17. Maximum sustained wind speed**   🖋️*needs to add knot(kt)*  \n```\nUnit : knot (kt)\n```\n**18. Direction of the longest radius of 50kt winds or greater** 🖋️ *needs to convert to denoted String from used Integer*   \n```\n0 : No direction (Longest radius of 50kt winds is 0)\n1 : Northeast (NE)\n2 : East (E)\n3 : Southeast (SE)\n4 : South (S)\n5 : Southwest (SW)\n6 : West (W)\n7 : Northwest (NW)\n8 : North (N)\n9 : (symmetric circle)\n```\n**19. The longest radius of 50kt winds or greater** 🖋️*needs to add nautical mile(nm)*  \n```\nUnit : nautical mile (nm)\n```\n**20. The shortest radius of 50kt winds or greater** 🖋️*needs to add nautical mile(nm)*   \n```\nUnit : nautical mile (nm)\n```                   \n**21. Direction of the longest radius of 30kt winds or greater** 🖋️ *needs to convert to denoted String from used Integer*  \n```\n0 : No direction (Longest radius of 30kt winds is 0)\n1 : Northeast (NE)\n2 : East (E)\n3 : Southeast (SE)\n4 : South (S)\n5 : Southwest (SW)\n6 : West (W)\n7 : Northwest (NW)\n8 : North (N)\n9 : (symmetric circle)\n```\n**22. The longest radius of 30kt winds or greater** 🖋️*needs to add nautical mile(nm)* \n```\nUnit : nautical mile (nm)\n```\n**23. The shortest radius of 30kt winds or greater** 🖋️*needs to add nautical mile(nm)* \n```\nUnit : nautical mile (nm)\n```\n**24. Indicator of landfall or passage** 🖋️*needs to add explaination* \n```\nLandfall or passage over the Japanese islands occurred within one hour after the time of the analysis with this indicator.\n```","metadata":{}},{"cell_type":"markdown","source":"Now, we shall modify our CSV file.\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(r'/kaggle/working/data_header_data_merged.csv')\n\ndf_copy = df.copy()\n# drop the mentioned columns\ndf_copy = df_copy.drop(['Indicator', 'Number of data lines', 'International number ID 2',\n                        'Flag of the last data line', 'Tropical cyclone number ID',\n                        'Difference between the time of the last data and the time of the final analysis', \n                        'Date of the latest revision', 'Indicator.1'], axis = 1)\ndf_copy = df_copy.rename(columns = {\"International number ID 1\": \"International number ID\"})\ndf_copy.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:06:12.081124Z","iopub.execute_input":"2023-10-02T10:06:12.081559Z","iopub.status.idle":"2023-10-02T10:06:12.355033Z","shell.execute_reply.started":"2023-10-02T10:06:12.081528Z","shell.execute_reply":"2023-10-02T10:06:12.354045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By right the Time of analysis should be in the format of Time, then we go to convert it into Time format.","metadata":{}},{"cell_type":"code","source":"# convert time\ndef convert_to_datetime(num):\n    # fill up the numbers that in years 2000+, because they are lack of 1 digit at the front, just simply fill up with 1 digit of 0.\n    num_str = str(num).zfill(8)\n    \n    # according to the format, extract the number\n    year = int(num_str[:2])\n    month = int(num_str[2:4])\n    day = int(num_str[4:6])\n    hour = int(num_str[6:])\n    \n    # since the first recorded data is from 1951, then we choose 51 as the pivot. \n    if year < 51:\n        year += 2000\n    else:\n        year += 1900\n    \n    \n    return pd.Timestamp(year=year, month=month, day=day,hour=hour)\n# update to the file\ndf_copy['Time of analysis'] = df_copy['Time of analysis'].apply(convert_to_datetime)\n\n\ndf_copy.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:07:16.498408Z","iopub.execute_input":"2023-10-02T10:07:16.49884Z","iopub.status.idle":"2023-10-02T10:07:17.117782Z","shell.execute_reply.started":"2023-10-02T10:07:16.49881Z","shell.execute_reply":"2023-10-02T10:07:17.116779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the format of some of the columns is not correct, it is time for us to organize it.","metadata":{}},{"cell_type":"code","source":"c = df_copy.select_dtypes(include=[object]).columns\ndf_copy[c] = df_copy[c].astype('string')\ndf_copy.to_csv(r'/kaggle/working/modified_data.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:08:33.023219Z","iopub.execute_input":"2023-10-02T10:08:33.024379Z","iopub.status.idle":"2023-10-02T10:08:33.480209Z","shell.execute_reply.started":"2023-10-02T10:08:33.024341Z","shell.execute_reply":"2023-10-02T10:08:33.479104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the format right now","metadata":{}},{"cell_type":"code","source":"data_types = df_copy.dtypes\n\n# print every data type\nfor column_name, data_type in data_types.items():\n    print(f\"Column '{column_name}' has data type: {data_type}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:09:09.769524Z","iopub.execute_input":"2023-10-02T10:09:09.769876Z","iopub.status.idle":"2023-10-02T10:09:09.776182Z","shell.execute_reply.started":"2023-10-02T10:09:09.769851Z","shell.execute_reply":"2023-10-02T10:09:09.774993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems better right now, let map the data!","metadata":{}},{"cell_type":"code","source":"import numpy as np\ncols_to_convert = ['Maximum sustained wind speed',\n                   'The longest radius of 50kt winds or greater',\n                   'The shortest radius of 50kt winds or greater',\n                   'The longest radius of 30kt winds or greater',\n                   'The shortest radius of 30kt winds or greater'\n                   ]\n\n# convert into integer\ndef convert_to_int(value):\n    try:\n        return int(value)\n    except ValueError:\n        return np.nan  # put it as NaN\n\nfor col in cols_to_convert:\n    df_copy[col] = df_copy[col].apply(convert_to_int)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:10:23.491226Z","iopub.execute_input":"2023-10-02T10:10:23.491588Z","iopub.status.idle":"2023-10-02T10:10:23.827892Z","shell.execute_reply.started":"2023-10-02T10:10:23.491562Z","shell.execute_reply":"2023-10-02T10:10:23.826799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_copy['Grade'] = df_copy['Grade'].astype(str)\ndata_types = df_copy.dtypes\n\nfor column_name, data_type in data_types.items():\n    print(f\"Column '{column_name}' has data type: {data_type}\")\ndf_copy.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:10:57.096372Z","iopub.execute_input":"2023-10-02T10:10:57.096684Z","iopub.status.idle":"2023-10-02T10:10:57.149834Z","shell.execute_reply.started":"2023-10-02T10:10:57.096662Z","shell.execute_reply":"2023-10-02T10:10:57.148621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Map the data according to the explaination from JMA.","metadata":{}},{"cell_type":"code","source":"column_name = 'Grade'\n\n# Explaination from JMA\nmapping_dict = {\n    '1': 'Not used',\n    '2': 'Tropical Depression (TD)',\n    '3': 'Tropical Storm (TS)',\n    '4': 'Severe Tropical Storm (STS)',\n    '5': 'Typhoon (TY)',\n    '6': 'Extra-tropical Cyclone (L)',\n    '7': 'Just entering into the responsible area of RSMC Tokyo-Typhoon Center',\n    '8': 'Not used',\n    '9': 'Tropical Cyclone of TS intensity or higher',\n}\n\n\ndf_copy[column_name] = df_copy[column_name].map(mapping_dict)\ndf_copy.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:11:47.964883Z","iopub.execute_input":"2023-10-02T10:11:47.965311Z","iopub.status.idle":"2023-10-02T10:11:48.001151Z","shell.execute_reply.started":"2023-10-02T10:11:47.96528Z","shell.execute_reply":"2023-10-02T10:11:48.000342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_name = 'Direction of the longest radius of 50kt winds or greater'\n\n\nmapping_dict = {\n    '0': 'No direction (Longest radius of 50kt winds is 0)',\n    '1': 'Northeast (NE)',\n    '2': 'East (E)',\n    '3': 'Southeast (SE)',\n    '4': 'South (S)',\n    '5': 'Southwest (SW)',\n    '6': 'West (W)',\n    '7': 'Northwest (NW)',\n    '8': 'North (N)',\n    '9': '(symmetric circle)',\n}\n\n\ndf_copy[column_name] = df_copy[column_name].map(mapping_dict)\ndf_copy.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:12:07.46101Z","iopub.execute_input":"2023-10-02T10:12:07.461413Z","iopub.status.idle":"2023-10-02T10:12:07.494524Z","shell.execute_reply.started":"2023-10-02T10:12:07.461386Z","shell.execute_reply":"2023-10-02T10:12:07.493304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_name = 'Direction of the longest radius of 30kt winds or greater'\n\n\nmapping_dict = {\n    '0': 'No direction (Longest radius of 50kt winds is 0)',\n    '1': 'Northeast (NE)',\n    '2': 'East (E)',\n    '3': 'Southeast (SE)',\n    '4': 'South (S)',\n    '5': 'Southwest (SW)',\n    '6': 'West (W)',\n    '7': 'Northwest (NW)',\n    '8': 'North (N)',\n    '9': '(symmetric circle)',\n}\n\n\ndf_copy[column_name] = df_copy[column_name].map(mapping_dict)\ndf_copy.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:12:24.179414Z","iopub.execute_input":"2023-10-02T10:12:24.180409Z","iopub.status.idle":"2023-10-02T10:12:24.214454Z","shell.execute_reply.started":"2023-10-02T10:12:24.180361Z","shell.execute_reply":"2023-10-02T10:12:24.21334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To match the real Latitude and Longitude!","metadata":{}},{"cell_type":"code","source":"df_copy['Latitude of the center'] = df_copy['Latitude of the center'] / 10\ndf_copy['Longitude of the center'] = df_copy['Longitude of the center'] / 10","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:14:32.729454Z","iopub.execute_input":"2023-10-02T10:14:32.729845Z","iopub.status.idle":"2023-10-02T10:14:32.739231Z","shell.execute_reply.started":"2023-10-02T10:14:32.729819Z","shell.execute_reply":"2023-10-02T10:14:32.737927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_copy.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:14:39.22118Z","iopub.execute_input":"2023-10-02T10:14:39.221577Z","iopub.status.idle":"2023-10-02T10:14:39.24372Z","shell.execute_reply.started":"2023-10-02T10:14:39.22155Z","shell.execute_reply":"2023-10-02T10:14:39.242677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_copy.to_csv(r'/kaggle/working/RSMC_Best_Track_Data.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:16:04.54654Z","iopub.execute_input":"2023-10-02T10:16:04.546898Z","iopub.status.idle":"2023-10-02T10:16:05.134836Z","shell.execute_reply.started":"2023-10-02T10:16:04.546873Z","shell.execute_reply":"2023-10-02T10:16:05.133779Z"},"trusted":true},"execution_count":null,"outputs":[]}]}